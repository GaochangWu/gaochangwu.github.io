<!DOCTYPE html>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Projectpage of ProtoNAS</title>
    <!-- Bootstrap -->
    <link href="./ProtoNAS_files/bootstrap-4.4.1.css" rel="stylesheet">
    <link rel="stylesheet" href="./ProtoNAS_files/font-awesome.min.css">
  <style id="MTQwMDAwMDE5OTk5OTky"></style><script type="text/javascript" charset="utf-8" defer="" async="" src="chrome-extension://acpjhbjgjlpeanfemfbbkabadjolngdk/inject-scripts/patch-xhr.js" data-params="{}"></script>
<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']]
    }
  };
</script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>

  <!-- cover -->
  <body><section>
    <div class="jumbotron text-center mt-0">
      <div class="container">
        <div class="row">
          <div class="col-12">
            <h2>ProtoNAS: Accelerating Differentiable Neural Architecture Search via Prototypical Data Pruning</h2>
            <h4 style="color:#5a6268;">TETCI 2025</h4>
            <hr>
            <h6>
                <a target="_blank">Liming Shi<sup>1</sup></a>,
                <a target="_blank">Lan Deng<sup>1</sup></a>,
                <a href="https://gaochangwu.github.io/" target="_blank">Gaochang Wu<sup>1✉</sup></a>,
                <a target="_blank"> Jingxin Zhang<sup>2</sup></a>,
                <a target="_blank"> Jinliang Ding<sup>1</sup></a></h6>
            <p><sup>1</sup>Northeastern University<sup>&nbsp;  &nbsp;2</sup>Swinburne University of Technology<sup>&nbsp;  &nbsp;✉</sup>Corresponding author
            </p>

            <div class="row justify-content-center">
              <div class="column">
                <p class="mb-5"><a class="btn btn-large btn-light" href="https://ieeexplore.ieee.org/document/11267098" role="button" target="_blank">
                  Paper</a> </p>
              </div>
<!--              <div class="column">-->
<!--                <p class="mb-5"><a class="btn btn-large btn-light" href="https://ieeexplore.ieee.org/document/11267098" role="button" target="_blank">-->
<!--                  Code</a></p>-->
<!--              </div>-->
            </div>
            
          </div>
        </div>
      </div>
    </div>
  </section>
  <br>

  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
          <h3>Abstract</h3>

          <p class="text-left"> In this paper, we take a close look at the efficient differentiable Neural Architecture Search (NAS) problem through the lens of data pruning. A key insight is that the core samples in the pruned dataset can be interpreted as support vectors for networks to make informed decisions. Therefore, we introduce ProtoNAS, an innovative prototypical data pruning method that dynamically and explicitly measures the prototypical distance of each data sample to its class-specific clustering centroid (i.e., prototype). These prototypes are dynamically updated on-the-fly throughout the search phase, enabling flexible data pruning that adjusts with the architectures and network parameters. Compared to conventional cross-entropy-based or Euclidean-based distances, the prototypical distance not only considers the distance between a sample and its class-specific prototype, but also the relative distances to the prototypes of other classes in the embedding space, facilitating more precise score assignment.
Furthermore, beyond sample pruning, we introduce a class pruning policy aimed at masking the classes with the lowest average scores. This additional policy is designed to further expedite the NAS without compromising the performance of the final searched architecture. Extensive experiments conducted on NAS-Bench-201 and NAS-Bench-1Shot1 search spaces demonstrate that ProtoNAS can achieve a significant 90\% pruning rate with minimal performance trade-offs or even improved performance when applied to DARTS and its variants, such as PC-DARTS and $\beta$-DARTS. Compared to State-Of-The-Art (SOTA) data pruning techniques, ProtoNAS achieves a superior balance between search performance and search cost.
          </p>
        </div>
      </div>
    </div>
  </section>
  <br>

  <section>
    <div class="container">
      <div class="row">
          <div class="col-12 text-center">
            <h3>Method</h3>
              <hr style="margin-top:0px">
            <img src="./ProtoNAS_files/Pipeline.png" width="100%" alt="" type="application/pdf">

            <p></p>
            <p>
              <strong>Overview of ProtoNAS for accelerating neural architecture search</strong>: (a) In the prototypical data pruning, we introduce a novel scoring metric that is based on the distance between a sample's feature vectors output by a specific feature layer in the supernet $\mathcal{F}^*_{\alpha^t,\omega^t}$ and its corresponding class-specific prototype. The prototypes are dynamically updated throughout the search phase. The score of a sample is formulated as the prototypical distance and its running variance. We then propose an innovative prototypical class pruning policy $\mathcal{P}_\mathcal{C}$ that efficiently accelerate the search phase without compromising the overall performance of the searched architecture. In addition, a class-aware sample pruning policy $\mathcal{P}_\mathcal{D}$ is introduced according to the score of each sample. The sample pruning policy is able to maintain the sample distribution of the dataset, circumventing class bias after the pruning. (b) The proposed prototypical data pruning promises lossless searching acceleration with significant pruning rate.
            </p>
            <p>&nbsp;</p>
			<img src="./ProtoNAS_files/prototype.png" width="50%" alt="">
            <p></p>
            <p>
              <strong>Illustration of prototypical distance in the embedding space. Samples $\textbf{x}_b$ can be assigned with a larger prototypical distance than samples $\textbf{x}_a$, despite having a smaller Euclidean distance. Therefore, the employed prototypical distance facilitates more precise score assignments compared to alternative scoring metrics.
            </p>
            <p>&nbsp;</p>
			<img src="./ProtoNAS_files/MPI.png" width="100%" alt="">
            <p></p>
<!--            <p>-->
<!--              <strong>MPI representation</strong>: The reconstruction cost produced by the proposed Geo-NI framework can be interpreted as alpha in the MPI representation. (a) We can promote the rendered 3D LF to MPIs for both input views and reconstructed views. We can also convert the reconstruction cost volume to (b) the EPI-MPI representation or (c) the vanilla version of MPI representation, simply by slicing along different dimensions.-->
<!--            </p>-->
            <p>&nbsp;</p>
          </div>
      </div>
    </div>
  </section>
  <br>
  
<!--  <section>-->
<!--    <div class="container">-->
<!--      <div class="row">-->
<!--        <div class="col-12 text-center">-->
<!--          <h3>Demo Video (with audio)</h3>-->
<!--            <hr style="margin-top:0px">-->
<!--          <h6 style="color:#8899a5"> Demo video for method, comparisons, further applications</h6>-->
<!--            <video width="100%" playsinline="" loop="loop" preload="" controls="">-->
<!--              <source src="https://cdn.neuiai.com/public/GeoNI.mp4" type="video/mp4">-->
<!--            </video>-->
<!--            <p>&nbsp;</p>-->
<!--              &lt;!&ndash; <br><br> &ndash;&gt;-->
<!--        </div>-->
<!--      </div>-->
<!--    </div>-->
<!--  </section>-->
<!--  <br>-->

  <section>
    <div class="container">
      <div class="row">
          <div class="col-12 text-center">
            <h3>Qualitative Comparisons</h3>
              <hr style="margin-top:0px">
            <img src="./ProtoNAS_files/acc-cost201.png" width="50%" alt="">
            <p></p>
            <p>
              <strong>NAS-Bench-201</strong>: Comparison of the comprehensive performance of different data pruning methods using PC-DARTS on NAS-Bench-201 (CIFAR10).
            </p>
            <p>&nbsp;</p>
			<img src="./ProtoNAS_files/acc-cost1shot1.png" width="50%" alt="">
            <p></p>
            <p>
              <strong>NAS-Bench-1shot1</strong>: Comparison of the comprehensive performance of different data pruning methods using PC-DARTS on NAS-Bench-1shot1 (Space 3).
            </p>
            <p>&nbsp;</p>

			<img src="./ProtoNAS_files/tSNE.png" width="50%" alt="">
            <p></p>
            <p>
              <strong>Data visualization</strong>: Distribution of samples at different stages when using the prototypical data pruning policy. (a) and (b) are the distributions of all samples and selected samples before class pruning, respectively. (c) and (d) are the distributions of all samples and selected samples after class pruning, respectively. The sample features are derived from the search phase of ProtoNAS (PC-DARTS) on NAS-Bench-1shot1-Space 1.
            </p>
            <p>&nbsp;</p>
          </div>
      </div>
    </div>
  </section>
  <br>

    <!-- citing -->
    <div class="container">
      <div class="row ">
        <div class="col-12">
            <h3>Citation</h3>
            <hr style="margin-top:0px">
                <pre style="background-color: #e9eeef;padding: 1.25em 1.5em">  <code>@ARTICLE{11267098,
  author={Shi, Liming and Deng, Lan and Wu, Gaochang and Zhang, Jingxin and Ding, Jinliang},
  journal={IEEE Transactions on Emerging Topics in Computational Intelligence},
  title={ProtoNAS: Accelerating Differentiable Neural Architecture Search via Prototypical Data Pruning},
  year={2025},
  volume={},
  number={},
  pages={1-15}}
                </code></pre>
            <hr>
        </div>
      </div>
    </div>
  
  <footer class="text-center" style="margin-bottom:10px">
      Thanks to <a href="https://lioryariv.github.io/" target="_blank">Lior Yariv</a> for the website template.
  </footer>




</body></html>
